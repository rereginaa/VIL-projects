{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4089f9c-d827-48a3-91a0-25ad9096b5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gym\n",
    "import collections\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca6a33b-897f-4f1e-bb86-877c6418ddda",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bk/km4jr97x4t3386lc8kvtzh300000gn/T/ipykernel_13756/1827703172.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc1_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc2_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc1_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc1_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc2_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_shape, action_space, fc1_dim, fc2_dim):\n",
    "        super(Network, self).__init__()\n",
    "        self.fc1 = nn.Linear(*input_shape, fc1_dim)\n",
    "        self.fc2 = nn.Linear(fc1_dim, fc2_dim)\n",
    "        self.fc3 = nn.Linear(fc2_dim, action_space)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, obs_dim, size, batch_size):\n",
    "        self.memory_size, self.batch_size = size, batch_size\n",
    "        self.mem_idx, self.size, = 0, 0\n",
    "        \n",
    "        self.obs = np.zeros([size, obs_dim], dtype = np.float32)\n",
    "        self.acts = np.zeros([size], dtype = np.float32)\n",
    "        self.rewards = np.zeros([size], dtype = np.float32)\n",
    "        self.obs_ = np.zeros([size, obs_dim], dtype = np.float32)\n",
    "        self.dones = np.zeros(size, dtype = np.float32)\n",
    "\n",
    "    def add(self, obs, acts, rewards, obs_, dones):\n",
    "        self.mem_idx = self.mem_idx % self.memory_size\n",
    "        \n",
    "        self.obs[self.mem_idx] = obs\n",
    "        self.obs_[self.mem_idx] = obs_\n",
    "        self.acts[self.mem_idx] = acts\n",
    "        self.rewards[self.mem_idx] = rewards\n",
    "        self.dones[self.mem_idx] = dones\n",
    "       \n",
    "        self.size = min(self.size + 1, self.memory_size)\n",
    "\n",
    "    def sample(self):\n",
    "        i = np.random.choice(self.size, size = self.batch_size, replace = False)\n",
    "        out = dict(obs = self.obs[i], obs_ = self.obs_[i], acts = self.acts[i], rewards = self.rewards[i], dones = self.dones[i])\n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.size)\n",
    "    \n",
    "class DQN_Solver:\n",
    "    def __init__(self, model, target_model, replay_buffer, learning_rate): \n",
    "        self.model = model\n",
    "        self.target_model = target_model\n",
    "        self.replay_buffer = replay_buffer\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr = learning_rate)\n",
    "    \n",
    "    def choose_action(self, obs, epsilon):\n",
    "        if random.random() < epsilon:\n",
    "            return random.randint(0, 1)\n",
    "        else:\n",
    "            return self.model.forward(obs).argmax().item()\n",
    "        \n",
    "    def train(self, batch_size, learning_rate, gamma): \n",
    "        samples = self.replay_buffer.sample()\n",
    "        \n",
    "        states = torch.FloatTensor(samples[\"obs\"])\n",
    "        actions = torch.LongTensor(samples[\"acts\"].reshape(-1, 1))\n",
    "        rewards = torch.FloatTensor(samples[\"rewards\"].reshape(-1, 1))\n",
    "        states_ = torch.FloatTensor(samples[\"obs_\"])\n",
    "        dones = torch.FloatTensor(samples[\"dones\"].reshape(-1,1))\n",
    "        \n",
    "        q_target_max = self.target_model(states_).max(1)[0].unsqueeze(1).detach()\n",
    "        target = rewards + gamma * q_target_max * dones\n",
    "        q_out = self.model(states)\n",
    "        q_a = q_out.gather(1, actions)\n",
    "        \n",
    "        loss = F.smooth_l1_loss(q_a, target)\n",
    "    \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "def main(): \n",
    "    np.random.seed(1)\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    \n",
    "    episodes = 1000\n",
    "    batch_size = 64\n",
    "    learning_rate = 0.001\n",
    "    buffer_len = 100000\n",
    "    \n",
    "    print_per_i = 100\n",
    "    target_update_period = 4\n",
    "    \n",
    "    eps_start = 1\n",
    "    eps_end = 0.001\n",
    "    eps_decay = 0.995\n",
    "    tau = 1*1e-2\n",
    "    max_step = 2000\n",
    "    gamma = 0.99\n",
    "\n",
    "    input_shape = env.observation_space.shape\n",
    "    action_space = env.action_space.n\n",
    "    fc1_dim = 1024\n",
    "    fc2_dim = 512\n",
    "    \n",
    "    Q = Network(input_shape, action_space, fc1_dim, fc2_dim)\n",
    "    Q_target = Network(input_shape, action_space, fc1_dim, fc2_dim)\n",
    "    Q_target.load_state_dict(Q.state_dict())\n",
    "\n",
    "    replay_buffer = ReplayBuffer(input_shape[0], size = buffer_len, batch_size = batch_size)\n",
    "\n",
    "    score = 0\n",
    "    score_sum = 0\n",
    "    best_reward = 0\n",
    "    epsilon = eps_start\n",
    "\n",
    "    for i in range(episodes):\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        for t in range(max_step):\n",
    "            a = DQN_Solver(Q, Q_target, replay_buffer, learning_rate).choose_action(obs = torch.from_numpy(s).float(), epsilon = epsilon)\n",
    "            s_prime, r, done, _ = env.step(a)\n",
    "            done_mask = 0.0 if done else 1.0\n",
    "            replay_buffer.add(s, a, r/100.0, s_prime, done_mask)\n",
    "            s = s_prime\n",
    "            \n",
    "            score += r\n",
    "            score_sum += r\n",
    "\n",
    "            if len(replay_buffer) >= batch_size:\n",
    "                DQN_Solver(Q, Q_target, replay_buffer, learning_rate).train(batch_size, learning_rate, gamma)\n",
    "                \n",
    "                if score > best_reward:\n",
    "                    best_reward = score\n",
    "                \n",
    "                if (t + 1) % target_update_period == 0:\n",
    "                    for target_param, local_param in zip(Q_target.parameters(), Q.parameters()):\n",
    "                        target_param.data.copy_(tau * local_param.data + (1.0 - tau) * target_param.data)    \n",
    "            if done:\n",
    "                break\n",
    "        epsilon = max(eps_end, epsilon * eps_decay)\n",
    "\n",
    "        if i % print_per_i == 0 and i!=0:\n",
    "            print(\"Episode: {}, Average Reward: {:.2f}, Epsilon : {:.2f}\".format(i, score_sum/print_per_i, epsilon))\n",
    "            score_sum = 0.0\n",
    "        score = 0\n",
    "        \n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de5b179-5b85-4723-a420-944fe319be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b11d016a-3f8c-48a1-9d2d-46427bd4f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, state_space, action_space, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.fc1 = nn.Linear(state_space, self.hidden_dim)\n",
    "        self.lstm = nn.LSTM(self.hidden_dim, self.hidden_dim, batch_first = True)\n",
    "        self.fc2 = nn.Linear(self.hidden_dim, action_space)\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x, (new_h, new_c) = self.lstm(x, (h, c))\n",
    "        x = self.fc2(x)\n",
    "        return x, new_h, new_c\n",
    "    \n",
    "    def init_hidden_state(self, batch_size, training):\n",
    "        if training is True:\n",
    "            h, c = torch.zeros([1, batch_size, self.hidden_dim]), torch.zeros([1, batch_size, self.hidden_dim])\n",
    "        else:\n",
    "            h, c = torch.zeros([1, 1, self.hidden_dim]), torch.zeros([1, 1, self.hidden_dim])\n",
    "        return h, c\n",
    "    \n",
    "class EpisodeMemory:\n",
    "    def __init__(self, lookup_step = 20, random_update = False, max_eps_num = 100, max_eps_len = 500, batch_size = 1):\n",
    "        self.random_update = random_update\n",
    "        self.max_eps_num = max_eps_num\n",
    "        self.max_eps_len = max_eps_len\n",
    "        self.batch_size = batch_size\n",
    "        self.lookup_step = lookup_step\n",
    "        self.memory = collections.deque(maxlen = self.max_eps_num)\n",
    "\n",
    "    def add(self, episode):\n",
    "        self.memory.append(episode)\n",
    "\n",
    "    def sample(self):\n",
    "        sampled_buffer = []\n",
    "        \n",
    "        if self.random_update: \n",
    "            sampled_episodes = random.sample(self.memory, self.batch_size)\n",
    "            min_step = self.max_eps_len\n",
    "            for episode in sampled_episodes:\n",
    "                min_step = min(min_step, len(episode)) \n",
    "\n",
    "            for episode in sampled_episodes:\n",
    "                if min_step > self.lookup_step: \n",
    "                    i = np.random.randint(0, len(episode) - self.lookup_step + 1)\n",
    "                    sample = episode.sample(random_update = self.random_update, lookup_step = self.lookup_step, i = i)\n",
    "                else:\n",
    "                    i = np.random.randint(0, len(episode) - min_step + 1) \n",
    "                    sample = episode.sample(random_update = self.random_update, lookup_step = min_step, i = i)\n",
    "                sampled_buffer.append(sample)\n",
    "        else:\n",
    "            i = np.random.randint(0, len(self.memory))\n",
    "            sampled_buffer.append(self.memory[idx].sample(random_update = self.random_update))\n",
    "        return sampled_buffer, len(sampled_buffer[0]['obs'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "class EpisodeBuffer:\n",
    "    def __init__(self):\n",
    "        self.obs = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.obs_ = []\n",
    "        self.dones = []\n",
    "\n",
    "    def add(self, new_eps):\n",
    "        self.obs.append(new_eps[0])\n",
    "        self.actions.append(new_eps[1])\n",
    "        self.rewards.append(new_eps[2])\n",
    "        self.obs_.append(new_eps[3])\n",
    "        self.dones.append(new_eps[4])\n",
    "\n",
    "    def sample(self, lookup_step, i, random_update = False,): \n",
    "        obs = np.array(self.obs)\n",
    "        actions = np.array(self.actions)\n",
    "        rewards = np.array(self.rewards)\n",
    "        obs_ = np.array(self.obs_)\n",
    "        dones = np.array(self.dones)\n",
    "\n",
    "        if random_update is True:\n",
    "            obs = obs[i:i+lookup_step]\n",
    "            actions = actions[i:i+lookup_step]\n",
    "            rewards = rewards[i:i+lookup_step]\n",
    "            obs_ = obs_[i:i+lookup_step]\n",
    "            dones = dones[i:i+lookup_step]\n",
    "        \n",
    "        out = dict(obs = obs, actions = actions, rewards = rewards, obs_ = obs_, dones = dones)\n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.obs))\n",
    "\n",
    "class DQN_Solver: \n",
    "    def __init__(self, model, target_model, learning_rate): \n",
    "        self.model = model\n",
    "        self.target_model = target_model\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr = learning_rate)\n",
    "    \n",
    "    def choose_action(self, obs, h, c, epsilon):\n",
    "        output = self.model.forward(obs, h, c)\n",
    "        if random.random() < epsilon:\n",
    "            return random.randint(0,1), output[1], output[2]\n",
    "        else:\n",
    "            return output[0].argmax().item(), output[1] , output[2]\n",
    "    \n",
    "    def train(self, q_net, target_q_net, episode_memory, batch_size=1, learning_rate=1e-3, gamma=0.99):\n",
    "        samples, seq_len = episode_memory.sample()\n",
    "        obs, actions, rewards, obs_, dones = [], [], [], [], []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            obs.append(samples[i][\"obs\"])\n",
    "            actions.append(samples[i][\"actions\"])\n",
    "            rewards.append(samples[i][\"rewards\"])\n",
    "            obs_.append(samples[i][\"obs_\"])\n",
    "            dones.append(samples[i][\"dones\"])\n",
    "\n",
    "        obs = np.array(obs)\n",
    "        actions = np.array(actions)\n",
    "        rewards = np.array(rewards)\n",
    "        obs_ = np.array(obs_)\n",
    "        dones = np.array(dones)\n",
    "\n",
    "        obs = torch.FloatTensor(obs.reshape(batch_size, seq_len, -1))\n",
    "        actions = torch.LongTensor(actions.reshape(batch_size, seq_len, -1))\n",
    "        rewards = torch.FloatTensor(rewards.reshape(batch_size, seq_len, -1))\n",
    "        obs_ = torch.FloatTensor(obs_.reshape(batch_size, seq_len, -1))\n",
    "        dones = torch.FloatTensor(dones.reshape(batch_size, seq_len, -1))\n",
    "\n",
    "        h_target, c_target = self.target_model.init_hidden_state(batch_size = batch_size, training = True)\n",
    "        q_target, _, _ = self.target_model(obs_, h_target, c_target)\n",
    "        q_target_max = q_target.max(2)[0].view(batch_size,seq_len,-1).detach()\n",
    "        targets = rewards + gamma * q_target_max * dones\n",
    "\n",
    "        h, c = self.model.init_hidden_state(batch_size = batch_size, training = True)\n",
    "        q_out, _, _ = self.model(obs, h, c)\n",
    "        q_a = q_out.gather(2, actions)\n",
    "   \n",
    "        loss = F.smooth_l1_loss(q_a, targets)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "def main(): \n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    np.random.seed(1)\n",
    "   \n",
    "    batch_size = 8\n",
    "    learning_rate = 0.001\n",
    "    buffer_len = 100000\n",
    "    min_eps_num = 20 #start training Q network\n",
    "    episodes = 10000\n",
    "    print_per_iter = 100\n",
    "    target_update_period = 4\n",
    "    eps_start = 0.1\n",
    "    eps_end = 0.001\n",
    "    eps_decay = 0.995\n",
    "    tau = 0.001\n",
    "    max_step = 500\n",
    "    gamma = 0.99\n",
    "\n",
    "    random_update = True\n",
    "    lookup_step = 20 \n",
    "    max_eps_len = 100 \n",
    "\n",
    "    state_space = env.observation_space.shape[0]-2\n",
    "    action_space = env.action_space.n\n",
    "    hidden_dim = 64\n",
    "    \n",
    "    Q = Network(state_space, action_space, hidden_dim)\n",
    "    Q_target = Network(state_space, action_space, hidden_dim)\n",
    "    Q_target.load_state_dict(Q.state_dict())\n",
    "\n",
    "    score = 0\n",
    "    score_sum = 0\n",
    "    epsilon = eps_start\n",
    "    \n",
    "    episode_memory = EpisodeMemory(random_update = random_update, max_eps_num = 100, max_eps_len = 600, batch_size = batch_size, lookup_step = lookup_step)\n",
    "    \n",
    "    eps = []\n",
    "    rewards = []\n",
    "    avg_rewards = []\n",
    "\n",
    "    for i in range(1, episodes):\n",
    "        s = env.reset()\n",
    "        obs = s[::2] #use only positions of cart & pole\n",
    "        done = False\n",
    "        episode_record = EpisodeBuffer()\n",
    "        h, c = Q.init_hidden_state(batch_size = batch_size, training = False)\n",
    "        \n",
    "        eps.append(i)\n",
    "\n",
    "        for t in range(max_step):\n",
    "            a, h, c = DQN_Solver(Q, Q_target, learning_rate).choose_action(torch.from_numpy(obs).float().unsqueeze(0).unsqueeze(0), h, c, epsilon)\n",
    "            s_prime, r, done, _ = env.step(a)\n",
    "            obs_prime = s_prime[::2]\n",
    "\n",
    "            done_mask = 0 if done else 1\n",
    "            episode_record.add([obs, a, r/100.0, obs_prime, done_mask])\n",
    "            obs = obs_prime\n",
    "            \n",
    "            score += r\n",
    "            score_sum += r\n",
    "\n",
    "            if len(episode_memory) >= min_eps_num:\n",
    "                DQN_Solver(Q, Q_target, learning_rate).train(Q, Q_target, episode_memory, batch_size=batch_size, learning_rate=learning_rate, gamma = gamma)\n",
    "                if t % target_update_period == 0:\n",
    "                    for target_param, local_param in zip(Q_target.parameters(), Q.parameters()): # <- soft update\n",
    "                            target_param.data.copy_(tau*local_param.data + (1.0 - tau)*target_param.data)\n",
    "            if done: break\n",
    "        episode_memory.add(episode_record)\n",
    "        \n",
    "        epsilon = max(eps_end, epsilon * eps_decay)\n",
    "        \n",
    "        rewards.append(score)\n",
    "        avg_rewards.append(np.mean(rewards))\n",
    "        if i % print_per_iter == 0:\n",
    "            print(\"Episode: {}, Score: {:.3f}, Epsilon: {:.3f}\".format(i, score_sum/i, epsilon))\n",
    "        score = 0\n",
    "    \n",
    "    env.close()\n",
    "    \n",
    "    plt.plot(eps, rewards)\n",
    "    plt.plot(eps, avg_rewards, color = 'g')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a228f735-d1a5-43a3-ae87-99d40efcc6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100, Score: 25.490, Epsilon: 0.061\n",
      "Episode: 200, Score: 22.850, Epsilon: 0.037\n",
      "Episode: 300, Score: 21.647, Epsilon: 0.022\n",
      "Episode: 400, Score: 21.328, Epsilon: 0.013\n",
      "Episode: 500, Score: 20.312, Epsilon: 0.008\n",
      "Episode: 600, Score: 19.562, Epsilon: 0.005\n",
      "Episode: 700, Score: 19.037, Epsilon: 0.003\n",
      "Episode: 800, Score: 19.073, Epsilon: 0.002\n",
      "Episode: 900, Score: 19.241, Epsilon: 0.001\n",
      "Episode: 1000, Score: 19.128, Epsilon: 0.001\n",
      "Episode: 1100, Score: 19.924, Epsilon: 0.001\n",
      "Episode: 1200, Score: 20.538, Epsilon: 0.001\n",
      "Episode: 1300, Score: 21.243, Epsilon: 0.001\n",
      "Episode: 1400, Score: 22.517, Epsilon: 0.001\n",
      "Episode: 1500, Score: 23.175, Epsilon: 0.001\n",
      "Episode: 1600, Score: 23.323, Epsilon: 0.001\n",
      "Episode: 1700, Score: 23.408, Epsilon: 0.001\n",
      "Episode: 1800, Score: 24.384, Epsilon: 0.001\n",
      "Episode: 1900, Score: 25.606, Epsilon: 0.001\n",
      "Episode: 2000, Score: 26.396, Epsilon: 0.001\n",
      "Episode: 2100, Score: 26.400, Epsilon: 0.001\n",
      "Episode: 2200, Score: 26.248, Epsilon: 0.001\n",
      "Episode: 2300, Score: 26.001, Epsilon: 0.001\n",
      "Episode: 2400, Score: 25.745, Epsilon: 0.001\n",
      "Episode: 2500, Score: 25.485, Epsilon: 0.001\n",
      "Episode: 2600, Score: 25.486, Epsilon: 0.001\n",
      "Episode: 2700, Score: 25.576, Epsilon: 0.001\n",
      "Episode: 2800, Score: 26.131, Epsilon: 0.001\n",
      "Episode: 2900, Score: 27.295, Epsilon: 0.001\n",
      "Episode: 3000, Score: 28.027, Epsilon: 0.001\n",
      "Episode: 3100, Score: 28.306, Epsilon: 0.001\n",
      "Episode: 3200, Score: 28.540, Epsilon: 0.001\n",
      "Episode: 3300, Score: 28.491, Epsilon: 0.001\n",
      "Episode: 3400, Score: 28.405, Epsilon: 0.001\n",
      "Episode: 3500, Score: 28.494, Epsilon: 0.001\n",
      "Episode: 3600, Score: 28.651, Epsilon: 0.001\n",
      "Episode: 3700, Score: 28.546, Epsilon: 0.001\n",
      "Episode: 3800, Score: 28.360, Epsilon: 0.001\n",
      "Episode: 3900, Score: 28.459, Epsilon: 0.001\n",
      "Episode: 4000, Score: 28.742, Epsilon: 0.001\n",
      "Episode: 4100, Score: 28.789, Epsilon: 0.001\n",
      "Episode: 4200, Score: 28.846, Epsilon: 0.001\n",
      "Episode: 4300, Score: 28.900, Epsilon: 0.001\n",
      "Episode: 4400, Score: 28.909, Epsilon: 0.001\n",
      "Episode: 4500, Score: 29.043, Epsilon: 0.001\n",
      "Episode: 4600, Score: 29.375, Epsilon: 0.001\n",
      "Episode: 4700, Score: 29.902, Epsilon: 0.001\n",
      "Episode: 4800, Score: 30.261, Epsilon: 0.001\n",
      "Episode: 4900, Score: 30.543, Epsilon: 0.001\n",
      "Episode: 5000, Score: 30.773, Epsilon: 0.001\n",
      "Episode: 5100, Score: 31.089, Epsilon: 0.001\n",
      "Episode: 5200, Score: 31.224, Epsilon: 0.001\n",
      "Episode: 5300, Score: 31.228, Epsilon: 0.001\n",
      "Episode: 5400, Score: 31.294, Epsilon: 0.001\n",
      "Episode: 5500, Score: 31.280, Epsilon: 0.001\n",
      "Episode: 5600, Score: 31.342, Epsilon: 0.001\n",
      "Episode: 5700, Score: 31.434, Epsilon: 0.001\n",
      "Episode: 5800, Score: 31.543, Epsilon: 0.001\n",
      "Episode: 5900, Score: 31.762, Epsilon: 0.001\n",
      "Episode: 6000, Score: 31.893, Epsilon: 0.001\n",
      "Episode: 6100, Score: 32.220, Epsilon: 0.001\n",
      "Episode: 6200, Score: 32.356, Epsilon: 0.001\n",
      "Episode: 6300, Score: 32.564, Epsilon: 0.001\n",
      "Episode: 6400, Score: 32.812, Epsilon: 0.001\n",
      "Episode: 6500, Score: 33.177, Epsilon: 0.001\n",
      "Episode: 6600, Score: 33.495, Epsilon: 0.001\n",
      "Episode: 6700, Score: 33.677, Epsilon: 0.001\n",
      "Episode: 6800, Score: 33.908, Epsilon: 0.001\n",
      "Episode: 6900, Score: 34.160, Epsilon: 0.001\n",
      "Episode: 7000, Score: 34.185, Epsilon: 0.001\n",
      "Episode: 7100, Score: 34.170, Epsilon: 0.001\n",
      "Episode: 7200, Score: 34.211, Epsilon: 0.001\n",
      "Episode: 7300, Score: 34.305, Epsilon: 0.001\n",
      "Episode: 7400, Score: 34.301, Epsilon: 0.001\n",
      "Episode: 7500, Score: 34.268, Epsilon: 0.001\n",
      "Episode: 7600, Score: 34.198, Epsilon: 0.001\n",
      "Episode: 7700, Score: 34.133, Epsilon: 0.001\n",
      "Episode: 7800, Score: 34.061, Epsilon: 0.001\n",
      "Episode: 7900, Score: 34.048, Epsilon: 0.001\n",
      "Episode: 8000, Score: 33.975, Epsilon: 0.001\n",
      "Episode: 8100, Score: 33.939, Epsilon: 0.001\n",
      "Episode: 8200, Score: 33.771, Epsilon: 0.001\n",
      "Episode: 8300, Score: 33.650, Epsilon: 0.001\n",
      "Episode: 8400, Score: 33.548, Epsilon: 0.001\n",
      "Episode: 8500, Score: 33.448, Epsilon: 0.001\n",
      "Episode: 8600, Score: 33.396, Epsilon: 0.001\n",
      "Episode: 8700, Score: 33.426, Epsilon: 0.001\n",
      "Episode: 8800, Score: 33.443, Epsilon: 0.001\n",
      "Episode: 8900, Score: 33.504, Epsilon: 0.001\n",
      "Episode: 9000, Score: 33.527, Epsilon: 0.001\n",
      "Episode: 9100, Score: 33.570, Epsilon: 0.001\n",
      "Episode: 9200, Score: 33.711, Epsilon: 0.001\n",
      "Episode: 9300, Score: 33.894, Epsilon: 0.001\n",
      "Episode: 9400, Score: 33.953, Epsilon: 0.001\n",
      "Episode: 9500, Score: 34.045, Epsilon: 0.001\n",
      "Episode: 9600, Score: 34.043, Epsilon: 0.001\n",
      "Episode: 9700, Score: 33.996, Epsilon: 0.001\n",
      "Episode: 9800, Score: 33.971, Epsilon: 0.001\n",
      "Episode: 9900, Score: 33.972, Epsilon: 0.001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede0114e-3ef0-4916-8b15-91edacc8834b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
